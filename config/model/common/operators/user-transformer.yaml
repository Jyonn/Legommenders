meta:
  user: Transformer
config:
  user_config:
    num_attention_heads: ${num_attention_heads:8}$
    num_hidden_layers: ${num_hidden_layers:3}$
    inputer_config:
      use_cls_token: false
      use_sep_token: false
