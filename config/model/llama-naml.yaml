name: LLAMA-NAML.D${model.config.hidden_size}.L${model.config.news_config.layer_split}.Lora${model.config.news_config.lora}
config:
  use_news_content: true
  use_fast_eval: ${fast_eval}$
  max_news_content_batch_size: ${max_news_batch_size}$
  same_dim_transform: false
  embed_hidden_size: ${embed_hidden_size}$
  hidden_size: ${hidden_size}$
  neg_count: 4
  news_config:
    llm_dir: /home/data1/qijiong/llama-${llm_ver}
    layer_split: ${layer}$
    lora: ${lora}$
    weights_dir: data/${data.name}/llama-${llm_ver}-split
  user_config:
    num_attention_heads: 12
    inputer_config:
      use_cls_token: false
      use_sep_token: false
